### Speech Emotion Recognition
- **Modules Used:**
  - **pandas**, **seaborn**, **librosa**, **librosa.display**, **warnings**, **Keras**, and other necessary Python libraries
- **Data Loading:**
  - Worked on **Toronto dataset** for speech emotion recognition
  - Loaded the dataset and inspected its structure
- **Data Visualization:**
  - Created a custom function to plot:
    - **Wave plots** of audio signals
    - **Spectrograms** for frequency analysis
- **Feature Extraction:**
  - Extracted features like **MFCCs** (Mel Frequency Cepstral Coefficients) from the audio data
- **Data Preprocessing:**
  - Preprocessed the extracted features to prepare for model training
- **Model:**
  - Built an **LSTM** model for sequence prediction
  - Trained the model on preprocessed features
- **Evaluation:**
  - Plotted **accuracy** and **loss** histograms during training to visualize performance
  - Evaluated the model using **Confusion Matrix** and **Classification Report** to assess classification performance
- **Tools:**
  - **Keras** for model building and training
  - **Librosa** for audio processing

### Download Toronto Dataset
https://www.kaggle.com/datasets/ejlok1/toronto-emotional-speech-set-tess

